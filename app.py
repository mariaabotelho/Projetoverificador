import streamlit as st
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
import os
import requests
from bs4 import BeautifulSoup
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.document_loaders import WebBaseLoader
import trafilatura

@dataclass
class SearchResult:
    title: str
    url: str
    snippet: str
    source: str
    date: Optional[str] = None
    excerpt: Optional[str] = None

class FakeNewsChecker:
    def __init__(self):
        self.groq_api_key = "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"
        self.llm = ChatGroq(
            temperature=0,
            groq_api_key=self.groq_api_key,
            model_name="llama3-8b-8192"
        )

        self.verification_prompt = PromptTemplate(
            input_variables=["query", "search_results", "article_excerpts", "article_urls", "confirming_excerpts", "contradicting_excerpts"],
            template="""Analise a seguinte afirma√ß√£o e determine se ela √© verdadeira ou falsa baseado nas evid√™ncias encontradas:

Afirma√ß√£o a ser verificada: {query}

Resultados da pesquisa encontrados:
{search_results}

Trechos relevantes dos artigos:
{article_excerpts}

URLs das fontes consultadas:
{article_urls}

Trechos que confirmam a afirma√ß√£o:
{confirming_excerpts}

Trechos que contradizem a afirma√ß√£o:
{contradicting_excerpts}

Por favor, forne√ßa:
1. Um resumo das principais evid√™ncias encontradas
2. An√°lise da credibilidade das fontes
3. Verifica√ß√£o de contradi√ß√µes ou inconsist√™ncias
4. Sua conclus√£o final sobre a veracidade da afirma√ß√£o
5. N√≠vel de confian√ßa na an√°lise (alto/m√©dio/baixo)
6. As URLs e as datas de todas as fontes consultadas"""
        )

        self.verification_chain = LLMChain(
            llm=self.llm,
            prompt=self.verification_prompt
        )

    def extract_excerpt(self, content: str) -> str:
        """Extrai um trecho relevante do conte√∫do"""
        if not content:
            return ""
        sentences = content.split('.')
        return '. '.join(sentences[:3]) + '.'

    def search_duckduckgo(self, query: str, max_results: int = 10) -> List[SearchResult]:
        """Realiza busca no DuckDuckGo e extrai os resultados"""
        url = f"https://duckduckgo.com/html/?q={query}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        results = []
        for article in soup.find_all('article', {'data-nrn': 'result'})[:max_results]:
            try:
                title_elem = article.find('a', {'data-testid': 'result-title-a'})
                title = title_elem.get_text(strip=True) if title_elem else ''
                url = title_elem.get('href') if title_elem else ''
                snippet_elem = article.find('div', {'data-result': 'snippet'})
                snippet = snippet_elem.get_text(strip=True) if snippet_elem else ''
                source_elem = article.find('p', class_='fOCEb2mA3YZTJXXjpgdS')
                source = source_elem.get_text(strip=True) if source_elem else ''
                date_elem = article.find('span', class_='MILR5XIVy9h75WrLvKiq')
                date = date_elem.get_text(strip=True) if date_elem else None

                if title and url:
                    results.append(SearchResult(
                        title=title,
                        url=url,
                        snippet=snippet,
                        source=source,
                        date=date
                    ))
            except Exception as e:
                st.error(f"Erro ao processar resultado: {e}")
                continue

        return results

    def extract_article_content(self, url: str) -> Optional[Tuple[str, str, str]]:
        """Extrai o conte√∫do do artigo usando m√∫ltiplos m√©todos"""
        try:
            downloaded = trafilatura.fetch_url(url)
            content = trafilatura.extract(downloaded, include_comments=False)

            if content:
                confirming_excerpt, contradicting_excerpt = self.extract_relevant_excerpts(content)
                return content, confirming_excerpt, contradicting_excerpt

            loader = WebBaseLoader(url)
            docs = loader.load()
            content = "\n".join(doc.page_content for doc in docs)

            if content:
                confirming_excerpt, contradicting_excerpt = self.extract_relevant_excerpts(content)
                return content, confirming_excerpt, contradicting_excerpt

            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')

            for elem in soup.find_all(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                elem.decompose()

            content = soup.get_text(separator='\n', strip=True)
            confirming_excerpt, contradicting_excerpt = self.extract_relevant_excerpts(content)
            return content, confirming_excerpt, contradicting_excerpt

        except Exception as e:
            st.error(f"Erro ao extrair conte√∫do de {url}: {e}")
            return None, None, None

    def extract_relevant_excerpts(self, content: str) -> Tuple[str, str]:
        """Extrai trechos relevantes que confirmam ou contradizem a afirma√ß√£o"""
        confirming_excerpt = ""
        contradicting_excerpt = ""

        if content:
            lines = content.split("\n")
            for line in lines:
                if "confirma" in line.lower():
                    confirming_excerpt += line + "\n"
                elif "contradiz" in line.lower():
                    contradicting_excerpt += line + "\n"

        return confirming_excerpt.strip(), contradicting_excerpt.strip()

    def verify_claim(self, query: str) -> Tuple[str, List[SearchResult]]:
        """Verifica uma afirma√ß√£o usando busca e an√°lise"""
        with st.status("Pesquisando fontes..."):
            search_results = self.search_duckduckgo(query)

        with st.status("Extraindo e analisando conte√∫do..."):
            articles_content = []
            article_excerpts = []
            article_urls = []
            confirming_excerpts = []
            contradicting_excerpts = []

            for result in search_results:
                content, confirming_excerpt, contradicting_excerpt = self.extract_article_content(result.url)
                if content:
                    articles_content.append(f"Fonte: {result.source}\nT√≠tulo: {result.title}\nConte√∫do: {content}\n")
                    article_excerpts.append(f"De {result.source}: '{self.extract_excerpt(content)}'")
                    article_urls.append(result.url)
                    if confirming_excerpt:
                        confirming_excerpts.append(f"De {result.source}: '{confirming_excerpt}'")
                    if contradicting_excerpt:
                        contradicting_excerpts.append(f"De {result.source}: '{contradicting_excerpt}'")
                result.excerpt = self.extract_excerpt(content) if content else ""

            search_summary = "\n".join([
                f"T√≠tulo: {r.title}\nFonte: {r.source}\nData: {r.date}\nResumo: {r.snippet}\n"
                for r in search_results
            ])

        with st.status("Gerando an√°lise final..."):
            analysis = self.verification_chain.run(
                query=query,
                search_results=search_summary,
                article_excerpts="\n".join(article_excerpts),
                article_urls="\n".join(article_urls),
                confirming_excerpts="\n".join(confirming_excerpts),
                contradicting_excerpts="\n".join(contradicting_excerpts)
            )

        return analysis, search_results


def create_sidebar():
    with st.sidebar:
        st.title("Sobre o Verifik")
        
        st.write("""
        O Verifik √© uma ferramenta de verifica√ß√£o de not√≠cias que surge da 
        necessidade de combater a desinforma√ß√£o em uma era de sobrecarga 
        informacional nas redes sociais.
        """)
        
        st.subheader("Objetivo")
        st.write("""
        Oferecer uma ferramenta que automatiza o processo de verifica√ß√£o,
        consultando m√∫ltiplas fontes e analisando a credibilidade das 
        informa√ß√µes de forma r√°pida e acess√≠vel.
        """)
        
        st.subheader("Criadoras")
        st.caption("Maria Botelho")
        st.caption("Clarissa Treptow")
        st.caption("Catarina Moll")

def show_usage_tips():
    with st.expander("üìù Dicas para obter melhores resultados"):
        st.info("""
        **Para uma verifica√ß√£o mais precisa:**
        
        1. **Ortografia correta**: Verifique a grafia dos nomes e palavras
        2. **Seja espec√≠fico**: Quanto mais detalhes, melhor ser√° a an√°lise
        3. **Inclua datas**: Quando poss√≠vel, especifique o per√≠odo do evento
        
        **Exemplo de uma boa consulta:**
        "Michael Phelps ganhou 8 medalhas de ouro nas Olimp√≠adas de Pequim em 2008"
        """)
        
        st.warning("""
        **Limita√ß√µes importantes:**
        - Base de dados limitada at√© 2022
        - Resultados podem variar dependendo das fontes dispon√≠veis
        """)
        
        st.error("""
        **Disclaimer**: O Verifik utiliza intelig√™ncia artificial para an√°lise.
        Embora busquemos a m√°xima precis√£o, recomendamos sempre verificar as
        fontes originais para informa√ß√µes cr√≠ticas.
        """)

def main():
    st.set_page_config(
        page_title="Verifik",
        page_icon="üîç",
        layout="wide"
    )

    create_sidebar()

    # Cabe√ßalho principal
    col_logo, col_title = st.columns([1, 4])
    with col_logo:
        st.image("logo verifik.png", width=200)
    with col_title:
    # Removendo o t√≠tulo redundante
        st.subheader("Verifica√ß√£o inteligente de not√≠cias")

    # Dicas de uso
    show_usage_tips()

    # Container principal
    with st.container():
        st.write("---")
        query = st.text_area(
            "Digite a afirma√ß√£o que deseja verificar:",
            height=100,
            placeholder="Ex: Brasil ganhou a Copa Am√©rica de 2019 vencendo o Peru na final"
        )
        
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            verify_button = st.button("Verificar", type="primary", use_container_width=True)

        if verify_button and query:
            checker = FakeNewsChecker()
            
            try:
                with st.spinner("Analisando..."):
                    analysis, results = checker.verify_claim(query)
                
                # Fun√ß√£o de classifica√ß√£o
                def classify_result(analysis_lower):
                    # Indicadores fortes de FALSO
                    false_indicators = [
                        "falsa",
                        "n√£o √© verdadeira",
                        "n√£o h√° evid√™ncias que suportem",
                        "√© incorreta",
                        "n√£o corresponde aos fatos"
                    ]
                    
                    # Indicadores fortes de VERDADEIRO
                    true_indicators = [
                        "verdadeira",
                        "√© correta",
                        "√© confirmada",
                        "evid√™ncias confirmam",
                        "fontes confirmam"
                    ]
                    
                    # Indicadores de INCONCLUSIVO
                    inconclusive_indicators = [
                        "n√£o h√° consenso",
                        "evid√™ncias s√£o inconclusivas",
                        "algumas fontes sugerem",
                        "embora",
                        "entretanto",
                        "por outro lado",
                        "mais estudos s√£o necess√°rios",
                        "evid√™ncia √© limitada",
                        "n√£o √© poss√≠vel concluir",
                        "√© amplamente contestada",
                        "h√° discord√¢ncia",
                        "nem todas as fontes concordam"
                    ]
                    
                    # Verificar se h√° indicadores de resultados mistos
                    has_mixed_evidence = any(indicator in analysis_lower for indicator in inconclusive_indicators)
                    
                    # Verificar se h√° termos que frequentemente aparecem juntos em evid√™ncias conflitantes
                    has_conflicting_terms = (
                        ("algumas" in analysis_lower and "outras" in analysis_lower) or
                        ("confirma" in analysis_lower and "contradiz" in analysis_lower) or
                        ("evid√™ncias" in analysis_lower and "contradit√≥rias" in analysis_lower)
                    )
                    
                    # L√≥gica de classifica√ß√£o
                    if has_mixed_evidence or has_conflicting_terms:
                        st.info("‚ÑπÔ∏è INCONCLUSIVO", icon=None)
                    elif any(indicator in analysis_lower for indicator in false_indicators):
                        st.error("‚ùå FALSO", icon=None)
                    elif any(indicator in analysis_lower for indicator in true_indicators):
                        st.success("‚úÖ VERDADEIRO", icon=None)
                    else:
                        st.info("‚ÑπÔ∏è INCONCLUSIVO", icon=None)  # Caso padr√£o se nenhum padr√£o claro for encontrado

                # Usar a nova fun√ß√£o de classifica√ß√£o
                analysis_lower = analysis.lower()
                classify_result(analysis_lower)
                
                # An√°lise detalhada em container
                with st.container():
                    st.markdown(analysis)
                    
                # Fontes em expanders
                for idx, result in enumerate(results, 1):
                    with st.expander(f"Fonte {idx}: {result.title}"):
                        st.write(f"**Fonte:** {result.source}")
                        st.write(f"**Data:** {result.date}")
                        st.write(f"**URL:** {result.url}")
                        if result.excerpt:
                            st.info(f"**Trecho relevante:** {result.excerpt}")

            except Exception as e:
                st.error(f"Ocorreu um erro durante a an√°lise: {str(e)}")

        elif verify_button:
            st.warning("Por favor, digite uma afirma√ß√£o para verificar.")


if __name__ == "__main__":
    main()
